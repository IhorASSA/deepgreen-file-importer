{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepGreen-DEMO-ver2",
      "provenance": [],
      "collapsed_sections": [
        "b-YpfCy_pfnF",
        "KULQhxErmv3g"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-YpfCy_pfnF"
      },
      "source": [
        "### Installation Project Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwtVn8f4QpEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28e71a9e-b4d9-4537-e607-80cf6cfa651a"
      },
      "source": [
        "!pip install SQLAlchemy GeoAlchemy2 geopandas PyDrive psycopg2 --upgrade\n",
        "!pip install geopandas oauth2client --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting SQLAlchemy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/9a/a343fec86d4eac510eadd7d0fe50d49df253b9ad86fa14f01d5af2f32be0/SQLAlchemy-1.4.13-cp37-cp37m-manylinux2014_x86_64.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 9.0MB/s \n",
            "\u001b[?25hCollecting GeoAlchemy2\n",
            "  Downloading https://files.pythonhosted.org/packages/87/41/8726b38ea83e6453678fcf542bf936b23389a9a2dd86fd4fc558548775d6/GeoAlchemy2-0.8.5-py2.py3-none-any.whl\n",
            "Collecting geopandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/bf/e9cefb69d39155d122b6ddca53893b61535fa6ffdad70bf5ef708977f53f/geopandas-0.9.0-py2.py3-none-any.whl (994kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 40.2MB/s \n",
            "\u001b[?25hRequirement already up-to-date: PyDrive in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Collecting psycopg2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/ae/98cb7a0cbb1d748ee547b058b14604bd0e9bf285a8e0cc5d148f8a8a952e/psycopg2-2.8.6.tar.gz (383kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 26.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy) (3.10.1)\n",
            "Requirement already satisfied, skipping upgrade: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy) (1.0.0)\n",
            "Collecting pyproj>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/72/d52e9ca81caef056062d71991b0e9b1d16af042245627c5d0e4916a36c4f/pyproj-3.0.1-cp37-cp37m-manylinux2010_x86_64.whl (6.5MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 41.9MB/s \n",
            "\u001b[?25hCollecting fiona>=1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/2a/404b22883298a3efe9c6ef8d67acbf2c38443fa366ee9cd4cd34e17626ea/Fiona-1.8.19-cp37-cp37m-manylinux1_x86_64.whl (15.3MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3MB 254kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.7.1)\n",
            "Requirement already satisfied, skipping upgrade: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (1.12.8)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->SQLAlchemy) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->SQLAlchemy) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.7/dist-packages (from pyproj>=2.2.0->geopandas) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (20.3.0)\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: click<8,>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/42/1e/947eadf10d6804bf276eb8a038bd5307996dceaaa41cfd21b7a15ec62f5d/cligj-0.7.1-py3-none-any.whl\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.17.4)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.28.1)\n",
            "Requirement already satisfied, skipping upgrade: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.26.3)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
            "Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.2.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (56.0.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.53.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.4.7)\n",
            "Building wheels for collected packages: psycopg2\n",
            "  Building wheel for psycopg2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for psycopg2: filename=psycopg2-2.8.6-cp37-cp37m-linux_x86_64.whl size=427421 sha256=3dbbd6d43c826736c60fe6031bff37874043cf84173e1bcf33d1a75c00c503c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/a5/85/8a05cfbb59d4ab25af2a0c82fb0e1b892ba104d6666aecd78c\n",
            "Successfully built psycopg2\n",
            "Installing collected packages: SQLAlchemy, GeoAlchemy2, pyproj, click-plugins, cligj, munch, fiona, geopandas, psycopg2\n",
            "  Found existing installation: SQLAlchemy 1.4.7\n",
            "    Uninstalling SQLAlchemy-1.4.7:\n",
            "      Successfully uninstalled SQLAlchemy-1.4.7\n",
            "  Found existing installation: psycopg2 2.7.6.1\n",
            "    Uninstalling psycopg2-2.7.6.1:\n",
            "      Successfully uninstalled psycopg2-2.7.6.1\n",
            "Successfully installed GeoAlchemy2-0.8.5 SQLAlchemy-1.4.13 click-plugins-1.1.1 cligj-0.7.1 fiona-1.8.19 geopandas-0.9.0 munch-2.5.0 psycopg2-2.8.6 pyproj-3.0.1\n",
            "Requirement already up-to-date: geopandas in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already up-to-date: oauth2client in /usr/local/lib/python3.7/dist-packages (4.1.3)\n",
            "Requirement already satisfied, skipping upgrade: pyproj>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (3.0.1)\n",
            "Requirement already satisfied, skipping upgrade: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.7.1)\n",
            "Requirement already satisfied, skipping upgrade: fiona>=1.8 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.19)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client) (0.17.4)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.7/dist-packages (from pyproj>=2.2.0->geopandas) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: munch in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: click-plugins>=1.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: click<8,>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (20.3.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KULQhxErmv3g"
      },
      "source": [
        "## Import Project Libraries\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohN9qIbUFaNs"
      },
      "source": [
        "import geopandas as gpd\n",
        "import folium\n",
        "import ftplib\n",
        "import json\n",
        "import logging as logger\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import psutil\n",
        "import requests\n",
        "import time\n",
        "\n",
        "from folium import Marker, GeoJson\n",
        "from folium.plugins import HeatMap\n",
        "from geopandas import GeoSeries\n",
        "from google.colab import auth\n",
        "from itertools import islice\n",
        "from multiprocessing import Pool\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from shapely.geometry import Polygon, Point, MultiPolygon\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "\n",
        "logger.basicConfig(\n",
        "    filename=\"log_file_test.log\",\n",
        "    filemode='a',\n",
        "    format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
        "    datefmt='%H:%M:%S',\n",
        "    level=logger.DEBUG\n",
        ")\n",
        "\n",
        "logger.info(\"This is a test log ..\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHbsKNoGoZj1"
      },
      "source": [
        "## Constants and functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMUhUFQ4o6W3"
      },
      "source": [
        "### Define Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9HXGqf4OFvr"
      },
      "source": [
        "EPSG = 3857\n",
        "URL = 'https://lk.ukrforest.com/map/get-point-info?point=[{},{}]'\n",
        "\n",
        "JSON_RESPONSE = {\n",
        "    'index': '',\n",
        "    'region': '',\n",
        "    'district': '',\n",
        "    'quarter': '',\n",
        "    'square': '',\n",
        "    'cutting_ticket_url': '',\n",
        "    'cutting_status': '',\n",
        "    'cutting_volume_approved': '',\n",
        "    'cutting_user': '',\n",
        "    'cutting_method': '',\n",
        "    'coords': {\n",
        "        'centroid': [],\n",
        "        # 'polygon': []\n",
        "    },\n",
        "    'raw_response': {},\n",
        "    'url': None\n",
        "}\n",
        "\n",
        "COMMA_LIST = ', , ,'\n",
        "STRONG_LIST = '<strong> <strong> <strong> <strong>' # 4.times('<strong> ').join() - так не можна Саша? :)\n",
        "CUT_STATUS = 'Рубка'\n",
        "CUT_STATUS_STARTED = 'Рубка - Розпочата'\n",
        "CUT_STATUS_CLOSED = 'Рубка - Закрита'\n",
        "CUT_STATUS_NOT_STARTED = 'Рубка - Не розпочата'\n",
        "COL_START = ['datetime', 'ID', 'CODE', 'CODE_TEXT', 'area', 'Extend', 'geometry']\n",
        "COL_INFO = ['region', 'district', 'quarter', 'square',\n",
        "            'cutting_ticket_url', 'cutting_status', 'cutting_volume_approved', \n",
        "            'cutting_user', 'cutting_method']\n",
        "COL_END = ['url', 'coords',\t'raw_response']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk0npOTrpCTG"
      },
      "source": [
        "### Code Functions & Routines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDLyTaSCp9iX"
      },
      "source": [
        "### System Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvBHiSkDGIKw"
      },
      "source": [
        "def setup_drive():\n",
        "  # 1. Authenticate and create the PyDrive client.\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  return GoogleDrive(gauth)\n",
        "\n",
        "def prepare_local_path():\n",
        "  # choose a local (colab) directory to store the data.\n",
        "  local_download_path = os.path.expanduser('./')\n",
        "  try:\n",
        "    os.makedirs(local_download_path)\n",
        "  except Exception as err: \n",
        "    if err.errno != 17:\n",
        "      print(help(err))\n",
        "  return local_download_path\n",
        "\n",
        "def download_files(id_list):\n",
        "  drive = setup_drive()\n",
        "  local_download_path = prepare_local_path()\n",
        "  \n",
        "  for id_file in id_list: \n",
        "    # Create & download by id.\n",
        "    try:\n",
        "      downloaded = drive.CreateFile({'id':id_file})\n",
        "      print('title: {}, id: {}'.format(downloaded['title'], downloaded['id']))\n",
        "      file_name = os.path.join(local_download_path, downloaded['title'])\n",
        "      print('downloading to {}'.format(file_name))\n",
        "      downloaded.GetContentFile(file_name)\n",
        "    except Exception as err:\n",
        "      print('[download_files]: file_name={}'.format(id_file), err)\n",
        "\n",
        "def download_from_ftp(file_list):\n",
        "  ftp_session = ftplib.FTP('194.44.29.184','ftp_exchange','rSac04jEr2ZuLXp4')\n",
        "    \n",
        "  for file_name in file_list:\n",
        "    local_file_name = prepare_local_path() + file_name\n",
        "    print('Trying download {}-file from FTP'.format(file_name))\n",
        "    ftp_session.retrbinary(\n",
        "        \"RETR \" + file_name, \n",
        "        open(local_file_name, 'wb').write\n",
        "    )\n",
        "    print('Downloaded {}-file from FTP to local path: {}'.format(file_name, local_file_name))\n",
        "  \n",
        "  ftp_session.quit()\n",
        "\n",
        "def make_sub_lists(list_in, chunk_size):\n",
        "    list_in = iter(list_in)\n",
        "    return iter(lambda: tuple(islice(list_in, chunk_size)), ())\n",
        "\n",
        "def make_centroid_sub_lists(gdf, chunk_size):\n",
        "    centroids = list(\n",
        "        zip(\n",
        "            gdf.index,\n",
        "            zip(\n",
        "                gdf.centroid.x.values,\n",
        "                gdf.centroid.y.values)\n",
        "        )\n",
        "    )\n",
        "    return make_sub_lists(centroids, chunk_size)\n",
        "\n",
        "def custom_draw(x):\n",
        "  if x['properties']['CODE'] == 1:\n",
        "    return {'fillColor': '#00ff00', 'fillOpacity': 0.5, 'weight': 2}\n",
        "  elif x['properties']['CODE'] == 2:\n",
        "    return {'fillColor': '#ff0000', 'fillOpacity': 0.5, 'weight': 2}\n",
        "  elif x['properties']['CODE'] == 3:\n",
        "    return {'fillColor': '#ff69b4', 'fillOpacity': 0.5, 'weight': 2}\n",
        "  elif x['properties']['CODE'] == 4:\n",
        "    return {'fillColor': '#0000ff', 'fillOpacity': 0.5, 'weight': 1}\n",
        "  else:\n",
        "    return {'fillColor': '#c0c0c0', 'fillOpacity': 0.5, 'weight': 1}\n",
        "\n",
        "def save_to_postgres(gdf, table_name):\n",
        "  engine = create_engine(\n",
        "      \"postgresql://deepgreen:deepgreen2021MT!@ec2-15-188-127-126.eu-west-3.compute.amazonaws.com:5432/deepgreen\"\n",
        "  )  \n",
        "  gdf.to_postgis(name=table_name, con=engine, if_exists='replace', index=True)\n",
        "\n",
        "def get_datetime_from_file(file_for_processing): \n",
        "  with open(file_for_processing, 'rb') as fd: \n",
        "    json_file = json.load(fd)\n",
        "  \n",
        "  # raise without excuse :) if any\n",
        "  return pd.to_datetime(json_file.get('name', '').replace('_', '-'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt5i8s9_sdcv"
      },
      "source": [
        "### Parsing API response and enriching data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1sRSusPmcR0"
      },
      "source": [
        "#### Parsing and rules identification utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEEeWm-WbaAD"
      },
      "source": [
        "def parse_response(response, result):\n",
        "  static_info = [item.strip() for item in COMMA_LIST.split(',')]\n",
        "  cutting_info = [item.strip() for item in STRONG_LIST.split('<strong>')]\n",
        "  try:\n",
        "      response_data = response.get('data', [{}])\n",
        "      if response_data:\n",
        "          _static_info = response_data[0].get('static', COMMA_LIST).split(',')\n",
        "          if _static_info != COMMA_LIST and len(_static_info) == len(static_info):\n",
        "              static_info = [item.strip() for item in _static_info]\n",
        "\n",
        "          _cutting_info = response_data[0].get('cutting', STRONG_LIST).split('<strong>')\n",
        "          if _cutting_info != STRONG_LIST and len(_cutting_info) == len(cutting_info):\n",
        "              cutting_info = [item.replace('</br>', '').replace('<br>', '').replace('</strong>', '').strip()\n",
        "                              for item in _cutting_info]\n",
        "              # if cutting_info[1] != '' and cutting_info[1].find('Закрита') == -1:\n",
        "              #     print(cutting_info)\n",
        "  except Exception as err:\n",
        "      print('Response={} | Error={}'.format(response, err))\n",
        "\n",
        "  result['region'] = static_info[0].strip()\n",
        "  result['district'] = static_info[1].strip()\n",
        "  result['quarter'] = static_info[2].strip()\n",
        "  result['square'] = static_info[3].strip()\n",
        "\n",
        "  result['cutting_ticket_url'] = cutting_info[0].strip()\n",
        "  result['cutting_status'] = cutting_info[1].strip()\n",
        "  result['cutting_volume_approved'] = cutting_info[2].strip()\n",
        "  result['cutting_user'] = cutting_info[3].strip()\n",
        "  result['cutting_method'] = cutting_info[4].strip()\n",
        "\n",
        "  return result\n",
        "\n",
        "def set_rules_ver02(result): \n",
        "  \"\"\"\n",
        "    Rules prepared for DEMO-1 by Sash\n",
        "  \"\"\" \n",
        "  if result['region'] != '':\n",
        "    if CUT_STATUS_STARTED in result['cutting_status']:       # Legal\n",
        "      result['CODE'] = 1\n",
        "      result['CODE_TEXT'] = 'Легальна'\n",
        "    elif CUT_STATUS_CLOSED in result['cutting_status']:      # Not Legal\n",
        "      result['CODE'] = 2\n",
        "      result['CODE_TEXT'] = 'Не легальна (Рубка - Закрита)'\n",
        "    elif CUT_STATUS_NOT_STARTED in result['cutting_status']: # Not Legal | Don't started\n",
        "      result['CODE'] = 3\n",
        "      result['CODE_TEXT'] = 'Не легальна (Рубка - Не розпочата)'\n",
        "    else:\n",
        "      result['CODE'] = 5                                     # Unknown case\n",
        "      result['CODE_TEXT'] = 'Невідомий сценарій'\n",
        "  else:\n",
        "    result['CODE'] = 4                                     # User is not identified\n",
        "    result['CODE_TEXT'] = 'Не ідентифікований лісокористувач'\n",
        "   \n",
        "  return result\n",
        "  \n",
        "def set_rules_ver03(result): \n",
        "  \"\"\"\n",
        "    Rules prepared for DEMO-2 by Client&Team\n",
        "  \"\"\" \n",
        "  if result['region'] != '':\n",
        "    if CUT_STATUS_STARTED in result['cutting_status']:       # Legal\n",
        "      result['CODE'] = 1\n",
        "      result['CODE_TEXT'] = 'Легальна діюча'\n",
        "    elif CUT_STATUS_CLOSED in result['cutting_status']:      # Legal \"Closed\"\n",
        "      result['CODE'] = 2\n",
        "      result['CODE_TEXT'] = 'Легальна закрита'\n",
        "    elif CUT_STATUS_NOT_STARTED in result['cutting_status']: # Legal \"Don't started\"\n",
        "      result['CODE'] = 3\n",
        "      result['CODE_TEXT'] = 'Легальна не розпочата'\n",
        "    elif CUT_STATUS in result['cutting_status']:\n",
        "      result['CODE'] = 6                                     # Unknown case - \"Rubka Karl\", simply 'Rubka'\n",
        "      result['CODE_TEXT'] = 'Рубка'\n",
        "    else:\n",
        "      result['CODE'] = 4                                     # Not Legal\n",
        "      result['CODE_TEXT'] = 'Нелегальна відсутній лісорубний'\n",
        "  else:\n",
        "    result['CODE'] = 5                                       # Place is not identified\n",
        "    result['CODE_TEXT'] = 'Проблеми ідентифікації місцерозташування'\n",
        "  \n",
        "  return result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xnWMHskmsP7"
      },
      "source": [
        "#### Main Parsing and Enrichment Flow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAb9A328D6C-"
      },
      "source": [
        "def send_requests(polygon_flatten, rules_strategy='ver03'):\n",
        "    result_list = []\n",
        "    idx = 1\n",
        "    for idx, point in set(polygon_flatten):\n",
        "        result = JSON_RESPONSE.copy()\n",
        "        try:\n",
        "            result['index'] = idx\n",
        "            result.setdefault('coords', {})['centroid'] = point\n",
        "            # result.setdefault('coords', {})['polygon'] = polygon_flatten\n",
        "            url = URL.format(point[0], point[1])\n",
        "            result['url'] = url\n",
        "\n",
        "            response = requests.get(url).json()\n",
        "\n",
        "            result['raw_response'] = response\n",
        "            # Defaults\n",
        "            result = parse_response(response, result)\n",
        "            # Set the rules\n",
        "            if rules_strategy.lower() == 'ver02':\n",
        "              result = set_rules_ver02(result)\n",
        "            else:\n",
        "              result = set_rules_ver03(result)\n",
        "        except Exception as err:\n",
        "            result.setdefault('raw_response', err)\n",
        "            print('ERROR', url, result, err)\n",
        "        idx += 1\n",
        "        result_list.append(result)\n",
        "    print('Parsing is finished. Total requests in this session: {}'.format(len(result_list)))\n",
        "    return pd.DataFrame(result_list).set_index(keys='index')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxGN6drAsNwU"
      },
      "source": [
        "### Main multi-processing crawling flow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3yVU_63OWAR"
      },
      "source": [
        "def iterate_over_centroids(gdf, epsg=3857, limit=5, chunk_size=7):\n",
        "    num_cpus = psutil.cpu_count(logical=False)\n",
        "\n",
        "    #print(gdf.crs)\n",
        "    process_pool = Pool(processes=num_cpus*2)\n",
        "    start = time.time()\n",
        "\n",
        "    gdf_new = gdf.to_crs(epsg=epsg)\n",
        "    print(gdf_new.crs)\n",
        "\n",
        "    # Start processes in the pool and concat dataframes to one dataframe\n",
        "    dfs = process_pool.map( \n",
        "        send_requests,\n",
        "        [item for item in make_centroid_sub_lists(gdf_new.head(limit), chunk_size)]\n",
        "      )\n",
        "\n",
        "    df_processed = pd.concat(\n",
        "        dfs,\n",
        "        axis='rows',\n",
        "        ignore_index=False\n",
        "    )\n",
        "    gdf_merged = pd.concat(\n",
        "        [\n",
        "            gdf_new.head(limit),\n",
        "            df_processed\n",
        "        ],\n",
        "        axis='columns',\n",
        "        ignore_index=False\n",
        "    )\n",
        "    \n",
        "    gdf_merged = gdf_merged.reindex(list(COL_START + COL_INFO + COL_END), axis=1)\n",
        "    \n",
        "    gdf_merged.loc[:, 'CODE'] = gdf_merged.CODE.fillna(5)\n",
        "    gdf_merged.loc[:, 'CODE'] = gdf_merged.CODE.astype(int)                     \n",
        "    \n",
        "    gdf_merged.columns = [col.lower() for col in gdf_merged.columns]\n",
        "    print('Completed in: {} sec(s)'.format(time.time() - start))\n",
        "    \n",
        "    return gdf_merged\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG2ZkAiRst2e"
      },
      "source": [
        "## Main Flow Execution\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gudwslnDs2cj"
      },
      "source": [
        "### 1. Download file from FTP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiIE7ODmO8NH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9ef7536-65f2-4990-c589-5cb42a0725da"
      },
      "source": [
        "file_for_processing_1 = '2021_04_05.geojson'\n",
        "file_for_processing_2 = '2021_04_12.geojson'\n",
        "download_from_ftp([file_for_processing_1, file_for_processing_2])\n",
        "\n",
        "# Alternative - download from GDrive for demo purposes\n",
        "# download_files(\n",
        "    # [\n",
        "    #  '1T2YJJwQLHIM5SZtkGjUfgNLFSrbFJ_1m',\n",
        "    #  '17r3hZkNtuheIAZuXKCnhjHm1L9MHFkUq',\n",
        "    #  '1KLxqfuwrBWbv65l2EaxlcZptKfZ3zeqb',\n",
        "    #  '13_FPu_kYd5UngZ486B5hv0D_-7XboM3n'\n",
        "    #  ]\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trying download 2021_04_05.geojson-file from FTP\n",
            "Downloaded 2021_04_05.geojson-file from FTP to local path: ./2021_04_05.geojson\n",
            "Trying download 2021_04_12.geojson-file from FTP\n",
            "Downloaded 2021_04_12.geojson-file from FTP to local path: ./2021_04_12.geojson\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdD3jGDptf-b"
      },
      "source": [
        "### 2. Read and process downloaded *file*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWZ9dGF5qrKn",
        "outputId": "fc5fa1d3-815c-4ef6-ce84-01554728ec3f"
      },
      "source": [
        "# TEST\n",
        "# file_datetime = get_datetime_from_file(file_for_processing_2)\n",
        "# file_datetime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Timestamp('2021-04-12 00:00:00')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyQ3u2cFtgkW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "27401e6c-2d80-4016-8b74-20de8943309a"
      },
      "source": [
        "total_requests_to_process = 500\n",
        "\n",
        "gdf_aug = gpd.read_file(file_for_processing_1).to_crs(3857).tail(total_requests_to_process)\n",
        "file_datetime_1 = get_datetime_from_file(file_for_processing_1)\n",
        "gdf_aug.loc[:, 'datetime'] = file_datetime_1\n",
        "\n",
        "gdf_sep = gpd.read_file(file_for_processing_2).to_crs(3857).tail(total_requests_to_process)\n",
        "file_datetime_2 = get_datetime_from_file(file_for_processing_2)\n",
        "gdf_sep.loc[:, 'datetime'] = file_datetime_2\n",
        "\n",
        "gdf = pd.concat(\n",
        "    [\n",
        "      gdf_aug,\n",
        "      gdf_sep\n",
        "    ],\n",
        "    axis='rows',\n",
        "    ignore_index=True\n",
        ")\n",
        "# Normalize the index\n",
        "gdf.index = pd.Index([i for i in range(1, gdf.shape[0] + 1)])\n",
        "\n",
        "gdf.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>extend</th>\n",
              "      <th>ID</th>\n",
              "      <th>Date</th>\n",
              "      <th>geometry</th>\n",
              "      <th>datetime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>2021-04-05</td>\n",
              "      <td>MULTIPOLYGON (((3322035.542 6702249.028, 33220...</td>\n",
              "      <td>2021-04-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>2021-04-05</td>\n",
              "      <td>MULTIPOLYGON (((3314839.904 6696762.067, 33148...</td>\n",
              "      <td>2021-04-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>2021-04-05</td>\n",
              "      <td>MULTIPOLYGON (((3279688.743 6692973.141, 32797...</td>\n",
              "      <td>2021-04-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>2021-04-05</td>\n",
              "      <td>MULTIPOLYGON (((3375737.079 6690456.177, 33757...</td>\n",
              "      <td>2021-04-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>2021-04-05</td>\n",
              "      <td>MULTIPOLYGON (((3293319.329 6685962.656, 32933...</td>\n",
              "      <td>2021-04-05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   extend  ID  ...                                           geometry   datetime\n",
              "1       1  18  ...  MULTIPOLYGON (((3322035.542 6702249.028, 33220... 2021-04-05\n",
              "2       1  24  ...  MULTIPOLYGON (((3314839.904 6696762.067, 33148... 2021-04-05\n",
              "3       1  28  ...  MULTIPOLYGON (((3279688.743 6692973.141, 32797... 2021-04-05\n",
              "4       1  33  ...  MULTIPOLYGON (((3375737.079 6690456.177, 33757... 2021-04-05\n",
              "5       1  35  ...  MULTIPOLYGON (((3293319.329 6685962.656, 32933... 2021-04-05\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEQubT9vsa25",
        "outputId": "3f91f2df-a237-4693-b19f-a3702a0ba0cc"
      },
      "source": [
        "gdf.datetime.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['2021-04-05T00:00:00.000000000', '2021-04-12T00:00:00.000000000'],\n",
              "      dtype='datetime64[ns]')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg682EiaulgJ"
      },
      "source": [
        "### 3. Start crawling and parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk8GMGep-SWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d111d7-5b6a-4e17-d409-acfe524965ba"
      },
      "source": [
        "gdf_enriched = iterate_over_centroids(\n",
        "    gdf, \n",
        "    epsg=3857, \n",
        "    limit=total_requests_to_process, \n",
        "    chunk_size=25\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epsg:3857\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Parsing is finished. Total requests in this session: 25\n",
            "Completed in: 179.52968049049377 sec(s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fqoy3Wz0Tlc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33522872-4153-41e4-8d4f-456783f1988a"
      },
      "source": [
        "gdf_enriched.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
            "Int64Index: 500 entries, 1 to 500\n",
            "Data columns (total 19 columns):\n",
            " #   Column                   Non-Null Count  Dtype         \n",
            "---  ------                   --------------  -----         \n",
            " 0   datetime                 500 non-null    datetime64[ns]\n",
            " 1   id                       500 non-null    int64         \n",
            " 2   code                     500 non-null    int64         \n",
            " 3   code_text                500 non-null    object        \n",
            " 4   area                     0 non-null      float64       \n",
            " 5   extend                   0 non-null      float64       \n",
            " 6   geometry                 500 non-null    geometry      \n",
            " 7   region                   500 non-null    object        \n",
            " 8   district                 500 non-null    object        \n",
            " 9   quarter                  500 non-null    object        \n",
            " 10  square                   500 non-null    object        \n",
            " 11  cutting_ticket_url       500 non-null    object        \n",
            " 12  cutting_status           500 non-null    object        \n",
            " 13  cutting_volume_approved  500 non-null    object        \n",
            " 14  cutting_user             500 non-null    object        \n",
            " 15  cutting_method           500 non-null    object        \n",
            " 16  url                      500 non-null    object        \n",
            " 17  coords                   500 non-null    object        \n",
            " 18  raw_response             500 non-null    object        \n",
            "dtypes: datetime64[ns](1), float64(2), geometry(1), int64(2), object(13)\n",
            "memory usage: 78.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6edhdziT4g41",
        "outputId": "ea91de8e-702c-49e5-e537-996ddc6bfbbc"
      },
      "source": [
        "gdf_enriched.code.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 4, 1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "cVCQm8eIts17",
        "outputId": "9ba082fd-9077-4667-e770-c07d88e190c5"
      },
      "source": [
        "gdf_enriched[gdf_enriched.code == 3].head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>id</th>\n",
              "      <th>code</th>\n",
              "      <th>code_text</th>\n",
              "      <th>area</th>\n",
              "      <th>extend</th>\n",
              "      <th>geometry</th>\n",
              "      <th>region</th>\n",
              "      <th>district</th>\n",
              "      <th>quarter</th>\n",
              "      <th>square</th>\n",
              "      <th>cutting_ticket_url</th>\n",
              "      <th>cutting_status</th>\n",
              "      <th>cutting_volume_approved</th>\n",
              "      <th>cutting_user</th>\n",
              "      <th>cutting_method</th>\n",
              "      <th>url</th>\n",
              "      <th>coords</th>\n",
              "      <th>raw_response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>2021-04-05</td>\n",
              "      <td>252</td>\n",
              "      <td>3</td>\n",
              "      <td>Легальна не розпочата</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MULTIPOLYGON (((3328189.913 6594087.479, 33282...</td>\n",
              "      <td>ДП \"Іванківське лісове господарство\"</td>\n",
              "      <td>Леонівське лісництво</td>\n",
              "      <td>квартал - 15</td>\n",
              "      <td>виділ - 11</td>\n",
              "      <td>&lt;a href='/240285' target='_blank'&gt;КИ 001104&lt;/a&gt;</td>\n",
              "      <td>Рубка - Не розпочата</td>\n",
              "      <td>Дозволений об'єм заготівлі - 27 куб.м</td>\n",
              "      <td>Виконавець рубки - 0</td>\n",
              "      <td>Спосіб очищення - Збирання порубкових решток у...</td>\n",
              "      <td>https://lk.ukrforest.com/map/get-point-info?po...</td>\n",
              "      <td>{'centroid': (3360795.0770918014, 6596313.9563...</td>\n",
              "      <td>{'success': True, 'in_region': True, 'data': [...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>2021-04-05</td>\n",
              "      <td>491</td>\n",
              "      <td>3</td>\n",
              "      <td>Легальна не розпочата</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MULTIPOLYGON (((3467077.794 6524734.158, 34670...</td>\n",
              "      <td>ДП \"Бориспільське лісове господарство\"</td>\n",
              "      <td>Вишенківське лісництво</td>\n",
              "      <td>квартал - 68</td>\n",
              "      <td>виділ - 16.16</td>\n",
              "      <td>&lt;a href='/246134' target='_blank'&gt;КИ 013343&lt;/a&gt;</td>\n",
              "      <td>Рубка - Не розпочата</td>\n",
              "      <td>Дозволений об'єм заготівлі - 54 куб.м</td>\n",
              "      <td>Виконавець рубки - ПП \"ЮГАКВАТОРГ\"</td>\n",
              "      <td>Спосіб очищення - Комбінований</td>\n",
              "      <td>https://lk.ukrforest.com/map/get-point-info?po...</td>\n",
              "      <td>{'centroid': (3314979.2296013706, 6482524.8492...</td>\n",
              "      <td>{'success': True, 'in_region': True, 'data': [...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      datetime  ...                                       raw_response\n",
              "150 2021-04-05  ...  {'success': True, 'in_region': True, 'data': [...\n",
              "323 2021-04-05  ...  {'success': True, 'in_region': True, 'data': [...\n",
              "\n",
              "[2 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "kBaoWpVW8L_x",
        "outputId": "47176547-d233-4afd-a8c1-15cc52c58999"
      },
      "source": [
        "gdf_enriched[['code']].groupby(by='code').size().reset_index(name='counts')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>counts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>227</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   code  counts\n",
              "0     1       6\n",
              "1     2      11\n",
              "2     3       2\n",
              "3     4     254\n",
              "4     5     227"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tvv0-0ey5I7e"
      },
      "source": [
        "# gdf_enriched.loc[:, 'coords'] = gdf_enriched.coords.apply(lambda x: x.get('centroid'))\n",
        "# [MultiPolygon([feature]) if type(feature) == Polygon     else feature\n",
        "# gdf_enriched.loc[:, 'geometry'] = [MultiPolygon(list(x)) for x in gdf_enriched.coords]\n",
        "from shapely import wkt\n",
        "\n",
        "gdf_enriched_centroid = gdf_enriched[['code']].copy()\n",
        "gdf_enriched_centroid.loc[:, 'geometry'] = gdf_enriched.centroid.copy()\n",
        "gdf_enriched_centroid = gpd.GeoDataFrame(gdf_enriched_centroid, geometry='geometry')\n",
        "gdf_enriched_centroid.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8CJ7a0Qwo9L"
      },
      "source": [
        "### 4. Save enriched data to PostgreSQL DB\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9IVypkNAD_M"
      },
      "source": [
        "save_to_postgres(gdf_enriched, table_name='pg_deepgreen_demo_arsen')\n",
        "print('Data is saved. Please review the table [pg_deepgreen_demo_arsen]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d_sSW2dw-ik"
      },
      "source": [
        "### 5. Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "escQ4AsJxksL"
      },
      "source": [
        "# Load extra datasets\n",
        "# df_point = gpd.read_file('http://www.deepforest.org.ua/geo/point')\n",
        "# print(df_point.info())\n",
        "# df_point.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdLLjtl5xowz"
      },
      "source": [
        "# df_test = gpd.read_file('http://www.deepforest.org.ua/geo/test')\n",
        "# print(df_test.info())\n",
        "# df_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlNDwVS2WRyh"
      },
      "source": [
        "map_cache_url = 'https://mapa.ukrforest.com/mapcache/'\n",
        "cutting_url = 'https://mapa.ukrforest.com/wms'\n",
        "\n",
        "_map = folium.Map(\n",
        "    # location=[3358337.27, 6503873.82], \n",
        "    location=[46.168457, 31.331436],\n",
        "    tiles=\"cartodbpositron\",\n",
        "    # tiles=\"OpenStreetMap\",\n",
        "    crs='EPSG3857',\n",
        "    zoom_start=7,\n",
        ")\n",
        "\n",
        "folium.GeoJson(\n",
        "    gdf_enriched,\n",
        "    name=\"Cutting\", \n",
        "    style_function=custom_draw \n",
        ").add_to(_map)\n",
        "\n",
        "folium.GeoJson(\n",
        "    gdf_enriched_centroid,\n",
        "    name=\"Cutting-Centroids\", \n",
        "    #style_function=custom_draw \n",
        ").add_to(_map)\n",
        "\n",
        "# folium.WmsTileLayer(\n",
        "#     url=map_cache_url,\n",
        "#     name='forests',\n",
        "#     layers='forestries',\n",
        "#     frm='image/png'\n",
        "# ).add_to(m)\n",
        "\n",
        "folium.WmsTileLayer(\n",
        "    url=map_cache_url,\n",
        "    name='quarters',\n",
        "    layers='quarters',\n",
        "    frm='image/jpeg'\n",
        ").add_to(_map)\n",
        "\n",
        "folium.WmsTileLayer(\n",
        "    url=map_cache_url,\n",
        "    name='sections',\n",
        "    layers='sections',\n",
        "    frm='image/jpeg'\n",
        ").add_to(_map)\n",
        "\n",
        "folium.LayerControl().add_to(_map)\n",
        "_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVULTPqZVnfw"
      },
      "source": [
        "# folium.GeoJson(\n",
        "#     # gdf,#r'./DeepForest_GeoPoint.json', \n",
        "#     df_test.head(50),\n",
        "#     name=\"DeepForest_TEST\", \n",
        "#     style_function=custom_draw \n",
        "# ).add_to(_map)\n",
        "\n",
        "# folium.GeoJson(\n",
        "#     # gdf,#r'./DeepForest_GeoPoint.json', \n",
        "#     df_point.head(50),\n",
        "#     name=\"DeepForest_GeoPoint\", \n",
        "#     style_function=custom_draw \n",
        "# ).add_to(_map)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgoZn5EE4Pnk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}